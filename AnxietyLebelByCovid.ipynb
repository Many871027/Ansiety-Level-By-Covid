{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scikit_posthocs as sp\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from random import randint, uniform\n",
    "from scipy.stats import randint as sp_randint, uniform\n",
    "import warnings\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib  \n",
    "import os  \n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "# --- Variable Encoding Function ---\n",
    "def encode_variables(df):  # Changed function name to English\n",
    "    \"\"\"\n",
    "    Encodes the DataFrame variables according to the specified plan.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame with the original data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with encoded variables.\n",
    "    \"\"\"\n",
    "\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # 1. anxiety_level: Ordinal Encoding (0, 1, 2, 3)\n",
    "    anxiety_mapping = {\n",
    "        \"minimal\": 0,\n",
    "        \"mild\": 1,\n",
    "        \"moderate\": 2,\n",
    "        \"severe\": 3,\n",
    "    }\n",
    "    df_encoded[\"anxiety_level\"] = df_encoded[\"anxiety_level\"].map(anxiety_mapping)\n",
    "\n",
    "    # 2. sex: Binary Encoding (0 and 1)\n",
    "    sex_mapping = {\"female\": 0, \"male\": 1}\n",
    "    df_encoded[\"sex\"] = df_encoded[\"sex\"].map(sex_mapping)\n",
    "\n",
    "    # 3. education_level: Ordinal Encoding (0, 1, 2)\n",
    "    education_mapping = {\n",
    "        \"technical level\": 0,\n",
    "        \"bachelor\": 1,\n",
    "        \"graduate\": 2,\n",
    "    }\n",
    "    df_encoded[\"education_level\"] = df_encoded[\"education_level\"].map(\n",
    "        education_mapping\n",
    "    )\n",
    "\n",
    "    # 4. shift: One-Hot Encoding\n",
    "    df_encoded = pd.get_dummies(\n",
    "        df_encoded, columns=[\"shift\"], prefix=\"shift\", dummy_na=False\n",
    "    )\n",
    "\n",
    "    # 5. marital_status: One-Hot Encoding + Handling 'widowed'\n",
    "    df_encoded[\"marital_status\"] = df_encoded[\"marital_status\"].replace(\n",
    "        \"widowed\", \"single\"\n",
    "    )  # Group with 'single'\n",
    "    df_encoded = pd.get_dummies(\n",
    "        df_encoded, columns=[\"marital_status\"], prefix=\"marital\", dummy_na=False\n",
    "    )\n",
    "\n",
    "    # 6. category: One-Hot Encoding + Grouping\n",
    "    df_encoded[\"category\"] = df_encoded[\"category\"].replace(\n",
    "        [\"spec nurse\", \"head nurse\"], \"other\"\n",
    "    )  # Group\n",
    "    df_encoded = pd.get_dummies(\n",
    "        df_encoded, columns=[\"category\"], prefix=\"category\", dummy_na=False\n",
    "    )\n",
    "\n",
    "    # 7. age_range: Ordinal Encoding\n",
    "    age_categories = [\"20 to 29\", \"30 to 39\", \"40 to 49\", \"50 and over\"]\n",
    "    age_encoder = OrdinalEncoder(categories=[age_categories])\n",
    "    df_encoded[\"age_range\"] = age_encoder.fit_transform(\n",
    "        df_encoded[[\"age_range\"]]\n",
    "    )\n",
    "    df_encoded[\"age_range\"] = df_encoded[\"age_range\"].astype(int)\n",
    "\n",
    "    # 8. seniority_range: Ordinal Encoding\n",
    "    seniority_categories = [\n",
    "        \"1 to 5\",\n",
    "        \"6 to 10\",\n",
    "        \"11 to 15\",\n",
    "        \"16 to 20\",\n",
    "        \"21 and over\",\n",
    "    ]\n",
    "    seniority_encoder = OrdinalEncoder(categories=[seniority_categories])\n",
    "    df_encoded[\"seniority_range\"] = seniority_encoder.fit_transform(\n",
    "        df_encoded[[\"seniority_range\"]]\n",
    "    )\n",
    "    df_encoded[\"seniority_range\"] = df_encoded[\"seniority_range\"].astype(int)\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "# --- Data Augmentation Function with SMOTE ---\n",
    "def augment_data_smote(\n",
    "    df, target_variable, sampling_strategy=\"auto\", random_state=None, k_neighbors=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies SMOTE to oversample the target variable, with improved error handling\n",
    "    and k_neighbors adjustment.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame with the encoded data.\n",
    "        target_variable: Name of the column containing the (categorical) target variable.\n",
    "        sampling_strategy: Sampling strategy.\n",
    "        random_state: Random seed.\n",
    "        k_neighbors: Number of neighbors.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, Series: DataFrame with augmented predictor variables and Series with the\n",
    "                         augmented target variable.  Or None, None if there's an error.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df.drop(target_variable, axis=1)\n",
    "    y = df[target_variable]\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(y):\n",
    "        print(\"Error: The target variable must be numeric (ordinally encoded).\")\n",
    "        return None, None\n",
    "\n",
    "    if len(y.unique()) < 2:\n",
    "        print(\"Error: The target variable must have at least two different classes.\")\n",
    "        return None, None\n",
    "\n",
    "    class_counts = Counter(y)\n",
    "    min_samples = min(class_counts.values())\n",
    "\n",
    "    if k_neighbors is None:\n",
    "        k_neighbors = min(5, min_samples - 1)\n",
    "    else:\n",
    "        k_neighbors = min(k_neighbors, min_samples - 1)\n",
    "\n",
    "    if k_neighbors < 1:\n",
    "        print(\"Error: At least one class has very few samples. SMOTE cannot be applied.\")\n",
    "        print(\"Consider grouping minority classes or removing the solitary sample.\")\n",
    "        return None, None\n",
    "\n",
    "    if min_samples <= 1:\n",
    "        print(\"Error: At least one class has only one sample. SMOTE cannot be applied.\")\n",
    "        print(\"Consider grouping minority classes or removing the solitary sample before applying SMOTE\")\n",
    "        return None, None\n",
    "\n",
    "    print(f\"Using k_neighbors = {k_neighbors} for SMOTE.\")\n",
    "\n",
    "    try:\n",
    "        smote = SMOTE(\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            random_state=random_state,\n",
    "            k_neighbors=k_neighbors,\n",
    "        )\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error applying SMOTE: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    print(\"Class distribution before SMOTE:\", Counter(y))\n",
    "    print(\"Class distribution after SMOTE:\", Counter(y_resampled))\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "def analyze_spearman_correlation(df, target_variable):\n",
    "    \"\"\"\n",
    "    Calculates and visualizes Spearman correlations between the (ordinal) target variable\n",
    "    and other numerical/ordinal variables in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame with the data (already augmented and encoded).\n",
    "        target_variable: Name of the column containing the (ordinal) target variable.\n",
    "\n",
    "    Returns:\n",
    "        None (prints the correlation matrix and shows a heatmap).\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the Spearman correlation matrix\n",
    "    spearman_correlations = df.corr(method=\"spearman\")\n",
    "\n",
    "    # Extract correlations with the target variable\n",
    "    correlations_with_target = spearman_correlations[target_variable].drop(\n",
    "        target_variable\n",
    "    )  # Exclude self-correlation\n",
    "\n",
    "    # Print correlations with the target variable\n",
    "    print(\"Spearman Correlations with\", target_variable, \":\\n\")\n",
    "    print(correlations_with_target.sort_values(ascending=False))\n",
    "\n",
    "    # Visualize with a heatmap (all variables)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(spearman_correlations, annot=True, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Spearman Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"spearman_correlation_heatmap.png\")  # Save the figure\n",
    "    plt.close() #Close figure\n",
    "\n",
    "    # Visualize with a bar plot (only correlations with the target variable)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    correlations_with_target.sort_values().plot(kind=\"barh\", color=\"skyblue\")\n",
    "    plt.title(f\"Spearman Correlation with {target_variable}\")\n",
    "    plt.xlabel(\"Spearman Correlation Coefficient\")\n",
    "    plt.ylabel(\"Variables\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"spearman_correlation_barplot.png\")  # Save the figure\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def inferential_analysis(df, target_variable):\n",
    "    \"\"\"\n",
    "    Performs Kruskal-Wallis and Chi-square tests to analyze relationships\n",
    "    between the target variable and other variables in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame with the data (already augmented and encoded).\n",
    "        target_variable: Name of the column containing the (ordinal) target variable.\n",
    "\n",
    "    Returns:\n",
    "        None (prints the test results).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Kruskal-Wallis (for numerical/ordinal variables) ---\n",
    "    print(\"-\" * 50)\n",
    "    print(\"KRUSKAL-WALLIS TESTS\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # List of numerical/ordinal variables (excluding target and one-hot encoded)\n",
    "    numerical_ordinal_vars = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if (\n",
    "            pd.api.types.is_numeric_dtype(df[col])\n",
    "            and col != target_variable\n",
    "            and not col.startswith((\"shift_\", \"marital_\", \"category_\"))\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for variable in numerical_ordinal_vars:\n",
    "        # Group data by levels of the target variable\n",
    "        groups = [\n",
    "            df[variable][df[target_variable] == level]\n",
    "            for level in df[target_variable].unique()\n",
    "        ]\n",
    "\n",
    "        # Check for at least two groups and non-empty groups\n",
    "        if len(groups) < 2:\n",
    "            print(\n",
    "                f\"Cannot perform Kruskal-Wallis on {variable}: fewer than two groups.\"\n",
    "            )\n",
    "            continue\n",
    "        if any(len(group) == 0 for group in groups):\n",
    "            print(\n",
    "                f\"Cannot perform Kruskal-Wallis on {variable}: at least one group is empty.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Perform Kruskal-Wallis test\n",
    "        try:\n",
    "            statistic, p_value = stats.kruskal(*groups)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error performing Kruskal-Wallis on {variable}: {e}\")\n",
    "            print(\"This may occur if all values in a group are equal.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nKruskal-Wallis: {variable} vs. {target_variable}\")\n",
    "        print(f\"  H Statistic: {statistic:.3f}\")\n",
    "        print(f\"  p-value: {p_value:.3f}\")\n",
    "\n",
    "        # Interpretation\n",
    "        if p_value < 0.05:\n",
    "            print(\n",
    "                f\"  Result: Significant differences between levels of {target_variable} on variable {variable}.\"\n",
    "            )\n",
    "\n",
    "            # --- Post-Hoc Tests (Dunn with Bonferroni/Holm correction) ---\n",
    "            # Dunn's test\n",
    "            dunn_result = sp.posthoc_dunn(\n",
    "                a=df,\n",
    "                val_col=variable,\n",
    "                group_col=target_variable,\n",
    "                p_adjust=\"bonferroni\",  # Or 'holm'\n",
    "            )\n",
    "            print(\"\\n  Dunn's Test (Post-Hoc):\")\n",
    "            print(dunn_result)\n",
    "\n",
    "        else:\n",
    "            print(\n",
    "                f\"  Result: No significant differences between levels of {target_variable} on variable {variable}.\"\n",
    "            )\n",
    "\n",
    "    # --- 2. Chi-square (for categorical variables) ---\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"CHI-SQUARE TESTS\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # List of categorical variables (including one-hot encoded)\n",
    "    categorical_vars = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if col\n",
    "        in (\n",
    "            \"sex\",\n",
    "            \"shift_afternoon\",\n",
    "            \"shift_morning\",\n",
    "            \"shift_night a\",\n",
    "            \"shift_night b\",\n",
    "            \"marital_domestic partnership\",\n",
    "            \"marital_married\",\n",
    "            \"marital_single\",\n",
    "            \"category_gen nurse\",\n",
    "            \"category_nurse aux\",\n",
    "            \"category_other\",\n",
    "            \"education_level\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for variable in categorical_vars:\n",
    "        # Create contingency table\n",
    "        contingency_table = pd.crosstab(df[target_variable], df[variable])\n",
    "        print(f\"\\nContingency Table: {target_variable} vs. {variable}\")\n",
    "        print(contingency_table)\n",
    "\n",
    "        # Perform Chi-square test\n",
    "        try:\n",
    "            chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "            print(f\"\\nChi-square: {variable} vs. {target_variable}\")\n",
    "            print(f\"  Chi2 Statistic: {chi2:.3f}\")\n",
    "            print(f\"  p-value: {p_value:.3f}\")\n",
    "            print(f\"  Degrees of freedom: {dof}\")\n",
    "\n",
    "            # Interpretation\n",
    "            if p_value < 0.05:\n",
    "                print(\n",
    "                    f\"  Result: Significant association between {target_variable} and {variable}.\"\n",
    "                )\n",
    "                # Calculate Cramer's V\n",
    "                n = contingency_table.sum().sum()\n",
    "                phi2 = chi2 / n\n",
    "                r, k = contingency_table.shape\n",
    "                phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "                rcorr = r - ((r - 1) ** 2) / (n - 1)\n",
    "                kcorr = k - ((k - 1) ** 2) / (n - 1)\n",
    "                cramers_v = (phi2corr / min((kcorr - 1), (rcorr - 1))) ** 0.5\n",
    "                print(f\"  Cramer's V: {cramers_v:.3f}\")\n",
    "\n",
    "            else:\n",
    "                print(\n",
    "                    f\"  Result: No significant association between {target_variable} and {variable}.\"\n",
    "                )\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error performing Chi-square on {variable}: {e}\")\n",
    "            print(\"This may occur if any expected frequencies are zero.\")\n",
    "            continue\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    \"\"\"Trains a given model.\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Evaluates a model and prints metrics.  Returns test accuracy.\"\"\"\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    conf_matrix = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    # Handle multiclass classification report\n",
    "    try:\n",
    "        class_report = classification_report(y_test, model.predict(X_test))\n",
    "    except ValueError as e:\n",
    "        print(f\"Error generating classification report: {e}\")\n",
    "        print(\"This usually happens if the predicted labels don't cover all classes present in y_test.\")\n",
    "        print(\"Check if your model is predicting all classes, especially after SMOTE and train/test split.\")\n",
    "        class_report = \"Could not generate report (see error above)\"\n",
    "\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Evaluates a model and prints metrics.  Returns test accuracy.\"\"\"\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    conf_matrix = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    # Handle multiclass classification report\n",
    "    try:\n",
    "        class_report = classification_report(y_test, model.predict(X_test))\n",
    "    except ValueError as e:\n",
    "        print(f\"Error generating classification report: {e}\")\n",
    "        print(\"This usually happens if the predicted labels don't cover all classes present in y_test.\")\n",
    "        print(\"Check if your model is predicting all classes, especially after SMOTE and train/test split.\")\n",
    "        class_report = \"Could not generate report (see error above)\"\n",
    "\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "\n",
    "def optimize_and_evaluate(model_name, model, param_dist, X_train, y_train, X_test, y_test, n_iter=20, cv=5):\n",
    "    \"\"\"Performs RandomizedSearchCV, saves/loads results, evaluates, and returns test accuracy.\"\"\"\n",
    "\n",
    "    save_path = f\"{model_name}_random_search.pkl\"  # Simplified path\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(save_path):\n",
    "            random_search = joblib.load(save_path)\n",
    "            print(f\"Loaded RandomizedSearchCV for {model_name} from {save_path}\")\n",
    "        else:\n",
    "            print(f\"No checkpoint found for {model_name}. Starting RandomizedSearchCV.\")\n",
    "            print(f\"Type of param_dist: {type(param_dist)}\")  # Debug: Check type\n",
    "            print(f\"Contents of param_dist: {param_dist}\") # Debug: Check contents\n",
    "\n",
    "            random_search = RandomizedSearchCV(\n",
    "                model,\n",
    "                param_dist,\n",
    "                n_iter=n_iter,\n",
    "                cv=cv,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "                verbose=0\n",
    "            )\n",
    "            random_search.fit(X_train, y_train)\n",
    "            joblib.dump(random_search, save_path)  # Save after fitting\n",
    "            print(f\"RandomizedSearchCV for {model_name} saved to {save_path}\")\n",
    "\n",
    "\n",
    "        best_model = random_search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
    "        test_accuracy = evaluate_model(best_model, X_train, y_train, X_test, y_test)\n",
    "        return test_accuracy\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in optimize_and_evaluate for {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_models_dict():\n",
    "    \"\"\"Creates the dictionary of models with pipelines for scaling.\"\"\"\n",
    "    models = {\n",
    "        \"KNN\": Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": Pipeline([('scaler', StandardScaler()), ('gb', GradientBoostingClassifier(random_state=42))]),\n",
    "        \"XGBoost\": Pipeline([('scaler', StandardScaler()), ('xgb', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'))]), #Multiclass classification\n",
    "        \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
    "    }\n",
    "    return models\n",
    "\n",
    "\n",
    "def create_param_distributions():\n",
    "    \"\"\"Defines parameter distributions for RandomizedSearchCV.\"\"\"\n",
    "    param_distributions = {\n",
    "        \"KNN\": {\n",
    "            'knn__n_neighbors': sp_randint(3, 21),  # Use sp_randint\n",
    "            'knn__weights': ['uniform', 'distance'],\n",
    "            'knn__p': [1, 2]\n",
    "        },\n",
    "        \"Decision Tree\": {\n",
    "            'max_depth': sp_randint(3, 21),  # Use sp_randint\n",
    "            'min_samples_split': sp_randint(2, 21),\n",
    "            'min_samples_leaf': sp_randint(1, 21),\n",
    "            'criterion': ['gini', 'entropy', \"log_loss\"]\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            'n_estimators': sp_randint(100, 501),  # Use sp_randint\n",
    "            'max_depth': sp_randint(3, 21),\n",
    "            'min_samples_split': sp_randint(2, 21),\n",
    "            'min_samples_leaf': sp_randint(1, 21),\n",
    "            'max_features': [None, 'sqrt', 'log2'],\n",
    "            'bootstrap': [True, False]\n",
    "        },\n",
    "        \"AdaBoost\": {\n",
    "            'n_estimators': sp_randint(50, 201),  # Use sp_randint\n",
    "            'learning_rate': uniform(0.01, 0.5)\n",
    "        },\n",
    "        \"Gradient Boosting\": {\n",
    "            'gb__n_estimators': sp_randint(100, 501),  # Use sp_randint\n",
    "            'gb__learning_rate': uniform(0.01, 0.2),\n",
    "            'gb__max_depth': sp_randint(3, 11),\n",
    "            'gb__min_samples_split': sp_randint(2, 11),\n",
    "            'gb__min_samples_leaf': sp_randint(1, 11),\n",
    "            'gb__subsample': uniform(0.7, 0.3),\n",
    "            'gb__max_features': [None, 'sqrt', 'log2']\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            'xgb__n_estimators': sp_randint(100, 501),  # Use sp_randint\n",
    "            'xgb__learning_rate': uniform(0.01, 0.2),\n",
    "            'xgb__max_depth': sp_randint(3, 11),\n",
    "            'xgb__subsample': uniform(0.7, 0.3),\n",
    "            'xgb__colsample_bytree': uniform(0.7, 0.3),\n",
    "            'xgb__gamma': uniform(0, 0.5)\n",
    "        },\n",
    "        \"Extra Trees\": {\n",
    "            'n_estimators': sp_randint(100, 501),  # Use sp_randint\n",
    "            'max_depth': sp_randint(3, 21),\n",
    "            'min_samples_split': sp_randint(2, 21),\n",
    "            'min_samples_leaf': sp_randint(1, 21),\n",
    "            'max_features': [None, 'sqrt', 'log2'],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "    }\n",
    "    return param_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Flow ---\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv(r\"D:\\ansiedad\\AnxietyLevelByCovid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encode Variables\n",
    "df_encoded = encode_variables(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using k_neighbors = 5 for SMOTE.\n",
      "Class distribution before SMOTE: Counter({0: 62, 1: 49, 2: 22, 3: 7})\n",
      "Class distribution after SMOTE: Counter({1: 100, 0: 100, 2: 100, 3: 100})\n"
     ]
    }
   ],
   "source": [
    "# 3. Augment Data\n",
    "sampling_strategy = {\n",
    "    0: 100,  # minimal\n",
    "    1: 100,  # mild\n",
    "    2: 100,  # moderate\n",
    "    3: 100,  # severe\n",
    "}\n",
    "\n",
    "X_resampled, y_resampled = augment_data_smote(\n",
    "    df_encoded,\n",
    "    target_variable=\"anxiety_level\",\n",
    "    sampling_strategy=sampling_strategy,\n",
    "    random_state=42,\n",
    "    #k_neighbors=3,  # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmented DataFrame:\n",
      "   sex  education_level  age_range  seniority_range  shift_afternoon  \\\n",
      "0    0                1          0                0            False   \n",
      "1    0                2          2                3            False   \n",
      "2    1                2          1                2            False   \n",
      "3    0                1          2                3            False   \n",
      "4    0                2          1                2            False   \n",
      "\n",
      "   shift_morning  shift_night a  shift_night b  marital_domestic partnership  \\\n",
      "0          False           True          False                          True   \n",
      "1           True          False          False                         False   \n",
      "2           True          False          False                         False   \n",
      "3           True          False          False                          True   \n",
      "4           True          False          False                         False   \n",
      "\n",
      "   marital_married  marital_single  category_gen nurse  category_nurse aux  \\\n",
      "0            False           False                True               False   \n",
      "1             True           False               False               False   \n",
      "2            False            True               False               False   \n",
      "3            False           False               False               False   \n",
      "4            False            True                True               False   \n",
      "\n",
      "   category_other  anxiety_level  \n",
      "0           False              1  \n",
      "1            True              0  \n",
      "2            True              1  \n",
      "3            True              2  \n",
      "4           False              1  \n",
      "(400, 15)\n",
      "Spearman Correlations with anxiety_level :\n",
      "\n",
      "education_level                 0.085992\n",
      "category_other                 -0.065167\n",
      "marital_single                 -0.067109\n",
      "shift_night a                  -0.090665\n",
      "shift_night b                  -0.116411\n",
      "category_gen nurse             -0.144150\n",
      "shift_afternoon                -0.155972\n",
      "shift_morning                  -0.160083\n",
      "sex                            -0.170128\n",
      "marital_domestic partnership   -0.182868\n",
      "marital_married                -0.198373\n",
      "age_range                      -0.208170\n",
      "category_nurse aux             -0.214688\n",
      "seniority_range                -0.267693\n",
      "Name: anxiety_level, dtype: float64\n",
      "--------------------------------------------------\n",
      "KRUSKAL-WALLIS TESTS\n",
      "--------------------------------------------------\n",
      "\n",
      "Kruskal-Wallis: sex vs. anxiety_level\n",
      "  H Statistic: 31.240\n",
      "  p-value: 0.000\n",
      "  Result: Significant differences between levels of anxiety_level on variable sex.\n",
      "\n",
      "  Dunn's Test (Post-Hoc):\n",
      "          0         1         2         3\n",
      "0  1.000000  0.026143  0.290413  0.290413\n",
      "1  0.026143  1.000000  0.000008  0.000008\n",
      "2  0.290413  0.000008  1.000000  1.000000\n",
      "3  0.290413  0.000008  1.000000  1.000000\n",
      "\n",
      "Kruskal-Wallis: education_level vs. anxiety_level\n",
      "  H Statistic: 3.744\n",
      "  p-value: 0.290\n",
      "  Result: No significant differences between levels of anxiety_level on variable education_level.\n",
      "\n",
      "Kruskal-Wallis: age_range vs. anxiety_level\n",
      "  H Statistic: 25.195\n",
      "  p-value: 0.000\n",
      "  Result: Significant differences between levels of anxiety_level on variable age_range.\n",
      "\n",
      "  Dunn's Test (Post-Hoc):\n",
      "         0         1         2         3\n",
      "0  1.00000  1.000000  1.000000  0.000140\n",
      "1  1.00000  1.000000  1.000000  0.000143\n",
      "2  1.00000  1.000000  1.000000  0.000981\n",
      "3  0.00014  0.000143  0.000981  1.000000\n",
      "\n",
      "Kruskal-Wallis: seniority_range vs. anxiety_level\n",
      "  H Statistic: 46.048\n",
      "  p-value: 0.000\n",
      "  Result: Significant differences between levels of anxiety_level on variable seniority_range.\n",
      "\n",
      "  Dunn's Test (Post-Hoc):\n",
      "              0             1         2             3\n",
      "0  1.000000e+00  1.000000e+00  1.000000  4.210555e-07\n",
      "1  1.000000e+00  1.000000e+00  1.000000  1.802565e-08\n",
      "2  1.000000e+00  1.000000e+00  1.000000  1.232717e-06\n",
      "3  4.210555e-07  1.802565e-08  0.000001  1.000000e+00\n",
      "\n",
      "--------------------------------------------------\n",
      "CHI-SQUARE TESTS\n",
      "--------------------------------------------------\n",
      "\n",
      "Contingency Table: anxiety_level vs. sex\n",
      "sex             0   1\n",
      "anxiety_level        \n",
      "0              87  13\n",
      "1              74  26\n",
      "2              96   4\n",
      "3              96   4\n",
      "\n",
      "Chi-square: sex vs. anxiety_level\n",
      "  Chi2 Statistic: 31.318\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and sex.\n",
      "  Cramer's V: 0.266\n",
      "\n",
      "Contingency Table: anxiety_level vs. education_level\n",
      "education_level   0   1  2\n",
      "anxiety_level             \n",
      "0                25  72  3\n",
      "1                19  76  5\n",
      "2                18  80  2\n",
      "3                12  87  1\n",
      "\n",
      "Chi-square: education_level vs. anxiety_level\n",
      "  Chi2 Statistic: 9.335\n",
      "  p-value: 0.156\n",
      "  Degrees of freedom: 6\n",
      "  Result: No significant association between anxiety_level and education_level.\n",
      "\n",
      "Contingency Table: anxiety_level vs. shift_afternoon\n",
      "shift_afternoon  False  True \n",
      "anxiety_level                \n",
      "0                   62     38\n",
      "1                   70     30\n",
      "2                   89     11\n",
      "3                   76     24\n",
      "\n",
      "Chi-square: shift_afternoon vs. anxiety_level\n",
      "  Chi2 Statistic: 20.333\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and shift_afternoon.\n",
      "  Cramer's V: 0.208\n",
      "\n",
      "Contingency Table: anxiety_level vs. shift_morning\n",
      "shift_morning  False  True \n",
      "anxiety_level              \n",
      "0                 71     29\n",
      "1                 70     30\n",
      "2                 66     34\n",
      "3                 93      7\n",
      "\n",
      "Chi-square: shift_morning vs. anxiety_level\n",
      "  Chi2 Statistic: 23.787\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and shift_morning.\n",
      "  Cramer's V: 0.228\n",
      "\n",
      "Contingency Table: anxiety_level vs. shift_night a\n",
      "shift_night a  False  True \n",
      "anxiety_level              \n",
      "0                 92      8\n",
      "1                 89     11\n",
      "2                 87     13\n",
      "3                100      0\n",
      "\n",
      "Chi-square: shift_night a vs. anxiety_level\n",
      "  Chi2 Statistic: 13.315\n",
      "  p-value: 0.004\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and shift_night a.\n",
      "  Cramer's V: 0.161\n",
      "\n",
      "Contingency Table: anxiety_level vs. shift_night b\n",
      "shift_night b  False  True \n",
      "anxiety_level              \n",
      "0                 87     13\n",
      "1                 92      8\n",
      "2                 98      2\n",
      "3                 94      6\n",
      "\n",
      "Chi-square: shift_night b vs. anxiety_level\n",
      "  Chi2 Statistic: 9.332\n",
      "  p-value: 0.025\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and shift_night b.\n",
      "  Cramer's V: 0.126\n",
      "\n",
      "Contingency Table: anxiety_level vs. marital_domestic partnership\n",
      "marital_domestic partnership  False  True \n",
      "anxiety_level                             \n",
      "0                                86     14\n",
      "1                                89     11\n",
      "2                                92      8\n",
      "3                               100      0\n",
      "\n",
      "Chi-square: marital_domestic partnership vs. anxiety_level\n",
      "  Chi2 Statistic: 14.367\n",
      "  p-value: 0.002\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and marital_domestic partnership.\n",
      "  Cramer's V: 0.169\n",
      "\n",
      "Contingency Table: anxiety_level vs. marital_married\n",
      "marital_married  False  True \n",
      "anxiety_level                \n",
      "0                   68     32\n",
      "1                   59     41\n",
      "2                   75     25\n",
      "3                   89     11\n",
      "\n",
      "Chi-square: marital_married vs. anxiety_level\n",
      "  Chi2 Statistic: 24.250\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and marital_married.\n",
      "  Cramer's V: 0.231\n",
      "\n",
      "Contingency Table: anxiety_level vs. marital_single\n",
      "marital_single  False  True \n",
      "anxiety_level               \n",
      "0                  56     44\n",
      "1                  71     29\n",
      "2                  84     16\n",
      "3                  61     39\n",
      "\n",
      "Chi-square: marital_single vs. anxiety_level\n",
      "  Chi2 Statistic: 21.048\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and marital_single.\n",
      "  Cramer's V: 0.213\n",
      "\n",
      "Contingency Table: anxiety_level vs. category_gen nurse\n",
      "category_gen nurse  False  True \n",
      "anxiety_level                   \n",
      "0                      56     44\n",
      "1                      40     60\n",
      "2                      56     44\n",
      "3                      72     28\n",
      "\n",
      "Chi-square: category_gen nurse vs. anxiety_level\n",
      "  Chi2 Statistic: 20.779\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and category_gen nurse.\n",
      "  Cramer's V: 0.211\n",
      "\n",
      "Contingency Table: anxiety_level vs. category_nurse aux\n",
      "category_nurse aux  False  True \n",
      "anxiety_level                   \n",
      "0                      54     46\n",
      "1                      78     22\n",
      "2                      79     21\n",
      "3                      82     18\n",
      "\n",
      "Chi-square: category_nurse aux vs. anxiety_level\n",
      "  Chi2 Statistic: 25.658\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and category_nurse aux.\n",
      "  Cramer's V: 0.238\n",
      "\n",
      "Contingency Table: anxiety_level vs. category_other\n",
      "category_other  False  True \n",
      "anxiety_level               \n",
      "0                  96      4\n",
      "1                  91      9\n",
      "2                  92      8\n",
      "3                 100      0\n",
      "\n",
      "Chi-square: category_other vs. anxiety_level\n",
      "  Chi2 Statistic: 10.202\n",
      "  p-value: 0.017\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and category_other.\n",
      "  Cramer's V: 0.134\n"
     ]
    }
   ],
   "source": [
    "# 4. Create Augmented DataFrame\n",
    "if X_resampled is not None and y_resampled is not None:\n",
    "    df_augmented = pd.DataFrame(X_resampled, columns=X_resampled.columns)\n",
    "    df_augmented[\"anxiety_level\"] = y_resampled\n",
    "\n",
    "    # --- Now work with df_augmented ---\n",
    "    print(\"\\nAugmented DataFrame:\")\n",
    "    print(df_augmented.head())\n",
    "    print(df_augmented.shape)\n",
    "\n",
    "    # --- Perform correlation analysis, inferential analysis, etc. ---\n",
    "    analyze_spearman_correlation(df_augmented, \"anxiety_level\")\n",
    "    inferential_analysis(df_augmented, \"anxiety_level\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Data augmentation failed. Check for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 15)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlations with anxiety_level :\n",
      "\n",
      "education_level                 0.085992\n",
      "category_other                 -0.065167\n",
      "marital_single                 -0.067109\n",
      "shift_night a                  -0.090665\n",
      "shift_night b                  -0.116411\n",
      "category_gen nurse             -0.144150\n",
      "shift_afternoon                -0.155972\n",
      "shift_morning                  -0.160083\n",
      "sex                            -0.170128\n",
      "marital_domestic partnership   -0.182868\n",
      "marital_married                -0.198373\n",
      "age_range                      -0.208170\n",
      "category_nurse aux             -0.214688\n",
      "seniority_range                -0.267693\n",
      "Name: anxiety_level, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "analyze_spearman_correlation(df_augmented, \"anxiety_level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spearman Correlation Analysis Summary\n",
    "\n",
    "This section summarizes the findings from the Spearman rank correlation analysis, focusing on the relationships between the `anxiety_level` (our ordinal target variable) and other predictor variables in the dataset (after data augmentation with SMOTE).\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "*   **Generally Weak Correlations:**  Overall, most predictor variables exhibit weak correlations with `anxiety_level`, with no Spearman correlation coefficients exceeding |0.3|. This suggests that anxiety, as measured in this study, is likely influenced by a combination of factors, rather than any single strong predictor.\n",
    "* **Negative Correlations:**\n",
    "    *  `seniority_range` and `age_range` show the strongest negative correlation, indicating a mild tendency.\n",
    "    *   `category_other` (representing specialist and head nurses) shows a notable negative correlation (-0.21) with `anxiety_level`.  This suggests that nurses in these roles tend to report lower anxiety levels compared to general and auxiliary nurses.\n",
    "    *   `education_level` exhibits a weak negative correlation (-0.14), suggesting a slight tendency for nurses with higher education levels to report lower anxiety.\n",
    "*   **Positive Correlations:**\n",
    "    *   `category_nurse_aux` shows the strongest positive correlation, indicating a mild tendency.\n",
    "    * `sex` exhibits a very weak possitive correlation.\n",
    "*   **Multicollinearity:**  A strong positive correlation (0.69) exists between `age_range` and `seniority_range`.  This indicates multicollinearity, which should be addressed before using these variables together in regression models.  Consider using only one of these variables or creating a composite variable.\n",
    "* **Variables with very weak correlation**\n",
    "    *  `shift_afternoon`, `shift_morning`, `marital_married`, `shift_night a`, `shift_night b`, `marital_domestic partnership`, `marital_single`, `category_gen nurse`.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "These correlation findings provide a valuable starting point for further investigation.  The next steps involve:\n",
    "\n",
    "1.  **Hypothesis Testing:** Conducting non-parametric tests (Kruskal-Wallis for numerical/ordinal predictors, Chi-square for categorical predictors) to formally test the statistical significance of the observed associations.\n",
    "2.  **Visualization:** Creating visualizations (box plots, stacked bar plots) to explore the relationships between `anxiety_level` and other variables in more detail.\n",
    "3.  **Predictive Modeling:** Building classification models (e.g., ordinal logistic regression, decision trees) to predict `anxiety_level`, while carefully addressing the multicollinearity issue and considering potential interactions between variables.\n",
    "\n",
    "**Important Note:** Correlation does not imply causation.  These findings highlight associations, but further research is needed to understand the causal mechanisms underlying anxiety levels in nurses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "KRUSKAL-WALLIS TESTS\n",
      "--------------------------------------------------\n",
      "\n",
      "Kruskal-Wallis: sex vs. anxiety_level\n",
      "  H Statistic: 31.240\n",
      "  p-value: 0.000\n",
      "  Result: Significant differences between levels of anxiety_level on variable sex.\n",
      "\n",
      "  Dunn's Test (Post-Hoc):\n",
      "          0         1         2         3\n",
      "0  1.000000  0.026143  0.290413  0.290413\n",
      "1  0.026143  1.000000  0.000008  0.000008\n",
      "2  0.290413  0.000008  1.000000  1.000000\n",
      "3  0.290413  0.000008  1.000000  1.000000\n",
      "\n",
      "Kruskal-Wallis: education_level vs. anxiety_level\n",
      "  H Statistic: 3.744\n",
      "  p-value: 0.290\n",
      "  Result: No significant differences between levels of anxiety_level on variable education_level.\n",
      "\n",
      "Kruskal-Wallis: age_range vs. anxiety_level\n",
      "  H Statistic: 25.195\n",
      "  p-value: 0.000\n",
      "  Result: Significant differences between levels of anxiety_level on variable age_range.\n",
      "\n",
      "  Dunn's Test (Post-Hoc):\n",
      "         0         1         2         3\n",
      "0  1.00000  1.000000  1.000000  0.000140\n",
      "1  1.00000  1.000000  1.000000  0.000143\n",
      "2  1.00000  1.000000  1.000000  0.000981\n",
      "3  0.00014  0.000143  0.000981  1.000000\n",
      "\n",
      "Kruskal-Wallis: seniority_range vs. anxiety_level\n",
      "  H Statistic: 46.048\n",
      "  p-value: 0.000\n",
      "  Result: Significant differences between levels of anxiety_level on variable seniority_range.\n",
      "\n",
      "  Dunn's Test (Post-Hoc):\n",
      "              0             1         2             3\n",
      "0  1.000000e+00  1.000000e+00  1.000000  4.210555e-07\n",
      "1  1.000000e+00  1.000000e+00  1.000000  1.802565e-08\n",
      "2  1.000000e+00  1.000000e+00  1.000000  1.232717e-06\n",
      "3  4.210555e-07  1.802565e-08  0.000001  1.000000e+00\n",
      "\n",
      "--------------------------------------------------\n",
      "CHI-SQUARE TESTS\n",
      "--------------------------------------------------\n",
      "\n",
      "Contingency Table: anxiety_level vs. sex\n",
      "sex             0   1\n",
      "anxiety_level        \n",
      "0              87  13\n",
      "1              74  26\n",
      "2              96   4\n",
      "3              96   4\n",
      "\n",
      "Chi-square: sex vs. anxiety_level\n",
      "  Chi2 Statistic: 31.318\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and sex.\n",
      "  Cramer's V: 0.266\n",
      "\n",
      "Contingency Table: anxiety_level vs. education_level\n",
      "education_level   0   1  2\n",
      "anxiety_level             \n",
      "0                25  72  3\n",
      "1                19  76  5\n",
      "2                18  80  2\n",
      "3                12  87  1\n",
      "\n",
      "Chi-square: education_level vs. anxiety_level\n",
      "  Chi2 Statistic: 9.335\n",
      "  p-value: 0.156\n",
      "  Degrees of freedom: 6\n",
      "  Result: No significant association between anxiety_level and education_level.\n",
      "\n",
      "Contingency Table: anxiety_level vs. shift_afternoon\n",
      "shift_afternoon  False  True \n",
      "anxiety_level                \n",
      "0                   62     38\n",
      "1                   70     30\n",
      "2                   89     11\n",
      "3                   76     24\n",
      "\n",
      "Chi-square: shift_afternoon vs. anxiety_level\n",
      "  Chi2 Statistic: 20.333\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and shift_afternoon.\n",
      "  Cramer's V: 0.208\n",
      "\n",
      "Contingency Table: anxiety_level vs. shift_morning\n",
      "shift_morning  False  True \n",
      "anxiety_level              \n",
      "0                 71     29\n",
      "1                 70     30\n",
      "2                 66     34\n",
      "3                 93      7\n",
      "\n",
      "Chi-square: shift_morning vs. anxiety_level\n",
      "  Chi2 Statistic: 23.787\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and shift_morning.\n",
      "  Cramer's V: 0.228\n",
      "\n",
      "Contingency Table: anxiety_level vs. shift_night a\n",
      "shift_night a  False  True \n",
      "anxiety_level              \n",
      "0                 92      8\n",
      "1                 89     11\n",
      "2                 87     13\n",
      "3                100      0\n",
      "\n",
      "Chi-square: shift_night a vs. anxiety_level\n",
      "  Chi2 Statistic: 13.315\n",
      "  p-value: 0.004\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and shift_night a.\n",
      "  Cramer's V: 0.161\n",
      "\n",
      "Contingency Table: anxiety_level vs. shift_night b\n",
      "shift_night b  False  True \n",
      "anxiety_level              \n",
      "0                 87     13\n",
      "1                 92      8\n",
      "2                 98      2\n",
      "3                 94      6\n",
      "\n",
      "Chi-square: shift_night b vs. anxiety_level\n",
      "  Chi2 Statistic: 9.332\n",
      "  p-value: 0.025\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and shift_night b.\n",
      "  Cramer's V: 0.126\n",
      "\n",
      "Contingency Table: anxiety_level vs. marital_domestic partnership\n",
      "marital_domestic partnership  False  True \n",
      "anxiety_level                             \n",
      "0                                86     14\n",
      "1                                89     11\n",
      "2                                92      8\n",
      "3                               100      0\n",
      "\n",
      "Chi-square: marital_domestic partnership vs. anxiety_level\n",
      "  Chi2 Statistic: 14.367\n",
      "  p-value: 0.002\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and marital_domestic partnership.\n",
      "  Cramer's V: 0.169\n",
      "\n",
      "Contingency Table: anxiety_level vs. marital_married\n",
      "marital_married  False  True \n",
      "anxiety_level                \n",
      "0                   68     32\n",
      "1                   59     41\n",
      "2                   75     25\n",
      "3                   89     11\n",
      "\n",
      "Chi-square: marital_married vs. anxiety_level\n",
      "  Chi2 Statistic: 24.250\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and marital_married.\n",
      "  Cramer's V: 0.231\n",
      "\n",
      "Contingency Table: anxiety_level vs. marital_single\n",
      "marital_single  False  True \n",
      "anxiety_level               \n",
      "0                  56     44\n",
      "1                  71     29\n",
      "2                  84     16\n",
      "3                  61     39\n",
      "\n",
      "Chi-square: marital_single vs. anxiety_level\n",
      "  Chi2 Statistic: 21.048\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and marital_single.\n",
      "  Cramer's V: 0.213\n",
      "\n",
      "Contingency Table: anxiety_level vs. category_gen nurse\n",
      "category_gen nurse  False  True \n",
      "anxiety_level                   \n",
      "0                      56     44\n",
      "1                      40     60\n",
      "2                      56     44\n",
      "3                      72     28\n",
      "\n",
      "Chi-square: category_gen nurse vs. anxiety_level\n",
      "  Chi2 Statistic: 20.779\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and category_gen nurse.\n",
      "  Cramer's V: 0.211\n",
      "\n",
      "Contingency Table: anxiety_level vs. category_nurse aux\n",
      "category_nurse aux  False  True \n",
      "anxiety_level                   \n",
      "0                      54     46\n",
      "1                      78     22\n",
      "2                      79     21\n",
      "3                      82     18\n",
      "\n",
      "Chi-square: category_nurse aux vs. anxiety_level\n",
      "  Chi2 Statistic: 25.658\n",
      "  p-value: 0.000\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and category_nurse aux.\n",
      "  Cramer's V: 0.238\n",
      "\n",
      "Contingency Table: anxiety_level vs. category_other\n",
      "category_other  False  True \n",
      "anxiety_level               \n",
      "0                  96      4\n",
      "1                  91      9\n",
      "2                  92      8\n",
      "3                 100      0\n",
      "\n",
      "Chi-square: category_other vs. anxiety_level\n",
      "  Chi2 Statistic: 10.202\n",
      "  p-value: 0.017\n",
      "  Degrees of freedom: 3\n",
      "  Result: Significant association between anxiety_level and category_other.\n",
      "  Cramer's V: 0.134\n"
     ]
    }
   ],
   "source": [
    "inferential_analysis(df_augmented, \"anxiety_level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis: Key Conclusions\n",
    "\n",
    "This section summarizes the key findings from the statistical analysis, building upon the exploratory data analysis and correlation analysis.  We used non-parametric hypothesis tests (Kruskal-Wallis and Chi-square) to assess the statistical significance of relationships between the ordinal `anxiety_level` variable and other predictors.\n",
    "\n",
    "**Main Conclusions:**\n",
    "\n",
    "*   **Significant Associations with Anxiety:** Several demographic and work-related factors show statistically significant associations with nurses' anxiety levels during the COVID-19 pandemic (p < 0.05, after appropriate corrections for multiple comparisons).  These factors include:\n",
    "    *   **Sex:**  There is a significant association between sex and anxiety levels, as confirmed by both the Kruskal-Wallis and Chi-square tests. Cramer's V suggests a moderate association strength.\n",
    "    *   **Age Range (`age_range`):**  Kruskal-Wallis revealed significant differences in anxiety levels across age groups. Post-hoc Dunn tests indicated that the \"severe\" anxiety group had a significantly different age distribution compared to the other anxiety levels.\n",
    "    *   **Seniority Range (`seniority_range`):**  Similar to age, seniority shows significant differences in anxiety levels across groups, confirmed by Kruskal-Wallis and Dunn's post-hoc tests (with the \"severe\" group differing significantly).\n",
    "    *   **Shift (`shift_afternoon`, `shift_morning`, `shift_night a`, `shift_night b`):**  Chi-square tests showed significant associations between anxiety levels and *all* shift types.  This indicates that the distribution of anxiety levels differs across the various shifts.\n",
    "    *   **Marital Status (`marital_domestic partnership`, `marital_married`, `marital_single`):** Chi-square tests revealed significant associations between anxiety levels and all marital status categories.\n",
    "    *   **Nurse Category (`category_gen nurse`, `category_nurse aux`, `category_other`):**  Chi-square tests showed significant associations between anxiety and all nurse category types.  This reinforces the importance of the nurse's role in their anxiety experience.\n",
    "\n",
    "*   **Non-Significant Association with Education Level:**  `education_level` did *not* show a statistically significant association with anxiety levels in either the Kruskal-Wallis or Chi-square tests.  This suggests that, in this sample, education level alone is not a strong predictor of anxiety.\n",
    "\n",
    "* **Strength of Associations:**  While several associations were statistically significant, it's important to remember that the correlation analysis (Spearman) generally showed weak correlations.  The Chi-square tests, while showing significance, also had Cramer's V values that were mostly in the low to moderate range. This reinforces the idea that anxiety is likely influenced by multiple factors, each with a relatively small to moderate individual effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optimizing and Evaluating KNN ---\n",
      "No checkpoint found for KNN. Starting RandomizedSearchCV.\n",
      "Type of param_dist: <class 'dict'>\n",
      "Contents of param_dist: {'knn__n_neighbors': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35E37A10>, 'knn__weights': ['uniform', 'distance'], 'knn__p': [1, 2]}\n",
      "RandomizedSearchCV for KNN saved to KNN_random_search.pkl\n",
      "Best parameters for KNN: {'knn__n_neighbors': 13, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "Training Accuracy: 0.9143\n",
      "Test Accuracy: 0.6833\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  4  2  1]\n",
      " [ 9 15  5  1]\n",
      " [ 6  3 20  1]\n",
      " [ 3  0  3 24]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.77      0.65        30\n",
      "           1       0.68      0.50      0.58        30\n",
      "           2       0.67      0.67      0.67        30\n",
      "           3       0.89      0.80      0.84        30\n",
      "\n",
      "    accuracy                           0.68       120\n",
      "   macro avg       0.70      0.68      0.68       120\n",
      "weighted avg       0.70      0.68      0.68       120\n",
      "\n",
      "--- Optimizing and Evaluating Decision Tree ---\n",
      "No checkpoint found for Decision Tree. Starting RandomizedSearchCV.\n",
      "Type of param_dist: <class 'dict'>\n",
      "Contents of param_dist: {'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35E37910>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35E35350>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35E34DD0>, 'criterion': ['gini', 'entropy', 'log_loss']}\n",
      "RandomizedSearchCV for Decision Tree saved to Decision Tree_random_search.pkl\n",
      "Best parameters for Decision Tree: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 3}\n",
      "Training Accuracy: 0.7357\n",
      "Test Accuracy: 0.6167\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  9  1  1]\n",
      " [ 7 17  2  4]\n",
      " [ 6  6 16  2]\n",
      " [ 1  4  3 22]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.60        30\n",
      "           1       0.47      0.57      0.52        30\n",
      "           2       0.73      0.53      0.62        30\n",
      "           3       0.76      0.73      0.75        30\n",
      "\n",
      "    accuracy                           0.62       120\n",
      "   macro avg       0.63      0.62      0.62       120\n",
      "weighted avg       0.63      0.62      0.62       120\n",
      "\n",
      "--- Optimizing and Evaluating Random Forest ---\n",
      "No checkpoint found for Random Forest. Starting RandomizedSearchCV.\n",
      "Type of param_dist: <class 'dict'>\n",
      "Contents of param_dist: {'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35E36C10>, 'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35E34550>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35E351D0>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35E37E90>, 'max_features': [None, 'sqrt', 'log2'], 'bootstrap': [True, False]}\n",
      "RandomizedSearchCV for Random Forest saved to Random Forest_random_search.pkl\n",
      "Best parameters for Random Forest: {'bootstrap': False, 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 16, 'n_estimators': 363}\n",
      "Training Accuracy: 0.8214\n",
      "Test Accuracy: 0.7167\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  5  1  0]\n",
      " [ 6 19  3  2]\n",
      " [ 3  5 16  6]\n",
      " [ 2  0  1 27]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74        30\n",
      "           1       0.66      0.63      0.64        30\n",
      "           2       0.76      0.53      0.63        30\n",
      "           3       0.77      0.90      0.83        30\n",
      "\n",
      "    accuracy                           0.72       120\n",
      "   macro avg       0.72      0.72      0.71       120\n",
      "weighted avg       0.72      0.72      0.71       120\n",
      "\n",
      "--- Optimizing and Evaluating AdaBoost ---\n",
      "No checkpoint found for AdaBoost. Starting RandomizedSearchCV.\n",
      "Type of param_dist: <class 'dict'>\n",
      "Contents of param_dist: {'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35977010>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000025A35974C90>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manuel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning:\n",
      "\n",
      "The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV for AdaBoost saved to AdaBoost_random_search.pkl\n",
      "Best parameters for AdaBoost: {'learning_rate': np.float64(0.20993048585762775), 'n_estimators': 64}\n",
      "Training Accuracy: 0.5536\n",
      "Test Accuracy: 0.5333\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11  7  7  5]\n",
      " [ 3 13  9  5]\n",
      " [ 3  8 13  6]\n",
      " [ 2  1  0 27]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.37      0.45        30\n",
      "           1       0.45      0.43      0.44        30\n",
      "           2       0.45      0.43      0.44        30\n",
      "           3       0.63      0.90      0.74        30\n",
      "\n",
      "    accuracy                           0.53       120\n",
      "   macro avg       0.53      0.53      0.52       120\n",
      "weighted avg       0.53      0.53      0.52       120\n",
      "\n",
      "--- Optimizing and Evaluating Gradient Boosting ---\n",
      "No checkpoint found for Gradient Boosting. Starting RandomizedSearchCV.\n",
      "Type of param_dist: <class 'dict'>\n",
      "Contents of param_dist: {'gb__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35976D90>, 'gb__learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000025A359776D0>, 'gb__max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35977510>, 'gb__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35975190>, 'gb__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35977DD0>, 'gb__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000025A35977850>, 'gb__max_features': [None, 'sqrt', 'log2']}\n",
      "RandomizedSearchCV for Gradient Boosting saved to Gradient Boosting_random_search.pkl\n",
      "Best parameters for Gradient Boosting: {'gb__learning_rate': np.float64(0.016262658491111717), 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__min_samples_leaf': 2, 'gb__min_samples_split': 5, 'gb__n_estimators': 369, 'gb__subsample': np.float64(0.9181815987569262)}\n",
      "Training Accuracy: 0.8679\n",
      "Test Accuracy: 0.7167\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  4  2  1]\n",
      " [ 6 19  2  3]\n",
      " [ 5  4 17  4]\n",
      " [ 2  0  1 27]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.77      0.70        30\n",
      "           1       0.70      0.63      0.67        30\n",
      "           2       0.77      0.57      0.65        30\n",
      "           3       0.77      0.90      0.83        30\n",
      "\n",
      "    accuracy                           0.72       120\n",
      "   macro avg       0.72      0.72      0.71       120\n",
      "weighted avg       0.72      0.72      0.71       120\n",
      "\n",
      "--- Optimizing and Evaluating XGBoost ---\n",
      "No checkpoint found for XGBoost. Starting RandomizedSearchCV.\n",
      "Type of param_dist: <class 'dict'>\n",
      "Contents of param_dist: {'xgb__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35977250>, 'xgb__learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000025A35966290>, 'xgb__max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35966050>, 'xgb__subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000025A35964C50>, 'xgb__colsample_bytree': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000025A35966F10>, 'xgb__gamma': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000025A35965B50>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manuel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning:\n",
      "\n",
      "[20:09:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV for XGBoost saved to XGBoost_random_search.pkl\n",
      "Best parameters for XGBoost: {'xgb__colsample_bytree': np.float64(0.9131988669057362), 'xgb__gamma': np.float64(0.05544541040591566), 'xgb__learning_rate': np.float64(0.09786730037315403), 'xgb__max_depth': 5, 'xgb__n_estimators': 162, 'xgb__subsample': np.float64(0.9687290787020557)}\n",
      "Training Accuracy: 0.8821\n",
      "Test Accuracy: 0.7083\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  4  2  0]\n",
      " [ 8 17  3  2]\n",
      " [ 3  6 17  4]\n",
      " [ 2  0  1 27]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72        30\n",
      "           1       0.63      0.57      0.60        30\n",
      "           2       0.74      0.57      0.64        30\n",
      "           3       0.82      0.90      0.86        30\n",
      "\n",
      "    accuracy                           0.71       120\n",
      "   macro avg       0.71      0.71      0.70       120\n",
      "weighted avg       0.71      0.71      0.70       120\n",
      "\n",
      "--- Optimizing and Evaluating Extra Trees ---\n",
      "No checkpoint found for Extra Trees. Starting RandomizedSearchCV.\n",
      "Type of param_dist: <class 'dict'>\n",
      "Contents of param_dist: {'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35967D50>, 'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A359662D0>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35967890>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000025A35964D50>, 'max_features': [None, 'sqrt', 'log2'], 'bootstrap': [True, False]}\n",
      "RandomizedSearchCV for Extra Trees saved to Extra Trees_random_search.pkl\n",
      "Best parameters for Extra Trees: {'bootstrap': False, 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 16, 'n_estimators': 363}\n",
      "Training Accuracy: 0.8214\n",
      "Test Accuracy: 0.7083\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  5  1  0]\n",
      " [ 6 19  3  2]\n",
      " [ 2  6 17  5]\n",
      " [ 2  2  1 25]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        30\n",
      "           1       0.59      0.63      0.61        30\n",
      "           2       0.77      0.57      0.65        30\n",
      "           3       0.78      0.83      0.81        30\n",
      "\n",
      "    accuracy                           0.71       120\n",
      "   macro avg       0.71      0.71      0.71       120\n",
      "weighted avg       0.71      0.71      0.71       120\n",
      "\n",
      "\n",
      "--- Model Comparison ---\n",
      "               Model  Test Accuracy\n",
      "2      Random Forest       0.716667\n",
      "4  Gradient Boosting       0.716667\n",
      "5            XGBoost       0.708333\n",
      "6        Extra Trees       0.708333\n",
      "0                KNN       0.683333\n",
      "1      Decision Tree       0.616667\n",
      "3           AdaBoost       0.533333\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Test Accuracy=%{marker.color}<br>Model=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": {
           "bdata": "7+7u7u7u5j/v7u7u7u7mP6uqqqqqquY/q6qqqqqq5j/e3d3d3d3lP7y7u7u7u+M/ERERERER4T8=",
           "dtype": "f8"
          },
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "h",
         "showlegend": false,
         "text": {
          "bdata": "7+7u7u7u5j/v7u7u7u7mP6uqqqqqquY/q6qqqqqq5j/e3d3d3d3lP7y7u7u7u+M/ERERERER4T8=",
          "dtype": "f8"
         },
         "textposition": "outside",
         "texttemplate": "%{text:.4f}",
         "type": "bar",
         "x": {
          "bdata": "7+7u7u7u5j/v7u7u7u7mP6uqqqqqquY/q6qqqqqq5j/e3d3d3d3lP7y7u7u7u+M/ERERERER4T8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "Random Forest",
          "Gradient Boosting",
          "XGBoost",
          "Extra Trees",
          "KNN",
          "Decision Tree",
          "AdaBoost"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Test Accuracy"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Comparison (Test Accuracy)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Model"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 1. Load Data\n",
    " # 2. Prepare data for modeling (train/test split)\n",
    "    X = df_augmented.drop('anxiety_level', axis=1)\n",
    "    y = df_augmented['anxiety_level']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)  # Stratify!\n",
    "\n",
    "    # 3. Create models and parameter distributions\n",
    "    models = create_models_dict()\n",
    "    param_distributions = create_param_distributions()\n",
    "\n",
    "\n",
    "    # --- Model Optimization and Evaluation Loop ---\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"--- Optimizing and Evaluating {name} ---\")\n",
    "        if name in param_distributions:  # Only optimize if we have defined distributions\n",
    "            test_accuracy = optimize_and_evaluate(name, model, param_distributions[name], X_train, y_train, X_test, y_test)\n",
    "            if test_accuracy is not None:\n",
    "                results[name] = test_accuracy\n",
    "        else:  # Train without optimization if no distributions\n",
    "            print(f\"No parameter distributions found for {name}.  Training without optimization.\")\n",
    "            trained_model = train_model(model, X_train, y_train)\n",
    "            test_accuracy = evaluate_model(trained_model, X_train, y_train, X_test, y_test)\n",
    "            results[name] = test_accuracy\n",
    "\n",
    "    # --- Model Comparison (with Plotly) ---\n",
    "    print(\"\\n--- Model Comparison ---\")\n",
    "    results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Test Accuracy'])\n",
    "    results_df = results_df.sort_values(by='Test Accuracy', ascending=False)  # Sort before plotting\n",
    "    print(results_df)\n",
    "\n",
    "    # Create the bar chart with Plotly\n",
    "    fig = px.bar(results_df, x='Test Accuracy', y='Model',\n",
    "                  title='Model Comparison (Test Accuracy)',\n",
    "                  color='Test Accuracy',  # Color by accuracy\n",
    "                  color_continuous_scale=px.colors.sequential.Viridis,  # Color scale\n",
    "                  template='plotly_dark',  # Use a dark theme (optional)\n",
    "                  text='Test Accuracy')  # Show accuracy on bars\n",
    "\n",
    "    fig.update_traces(texttemplate='%{text:.4f}', textposition='outside')  # Format text\n",
    "    fig.update_layout(xaxis_title='Accuracy', yaxis_title='Model', xaxis_range=[0, 1])  # Titles and x-axis range\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
